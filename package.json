{
  "name": "fast-api-ai-sdk",
  "description": "A production-ready template for building LLM chat applications with Next.js (Frontend) and FastAPI (Backend), managing state and streaming with the Vercel AI SDK.",
  "version": "0.1.0",
  "private": true,
  "packageManager": "pnpm@8.15.0",
  "workspaces": [
    "frontend",
    "backend"
  ],
  "scripts": {
    "fe:add": "cd frontend && pnpm add",
    "setup": "turbo run setup",
    "db": "docker-compose -f docker-compose.turbo.yml up -d",
    "dev": "pnpm db && turbo run dev",
    "build": "turbo run build",
    "lint": "turbo run lint",
    "lint:fix": "turbo run lint:fix",
    "format": "turbo run format",
    "format:check": "turbo run format:check",
    "check": "turbo run check",
    "check:fix": "turbo run check:fix",
    "type-check": "turbo run type-check",
    "clean": "turbo run clean",
    "postinstall": "turbo run setup"
  },
  "devDependencies": {
    "@biomejs/biome": "^2.3.11",
    "turbo": "^2.0.0"
  }
}
